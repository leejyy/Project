{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple&MultipleLinearRegressionAnalysis.R",
      "provenance": [],
      "authorship_tag": "ABX9TyNQ1qQlyDDol/N+oTCXHHMI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leejyy/Project/blob/main/Simple%26MultipleLinearRegressionAnalysis_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdscAPgqoO9P"
      },
      "outputs": [],
      "source": [
        "autompg0 <- read.table(\"auto-mpg.data\")\n",
        "autompg1 <- autompg0\n",
        "dim(autompg1)\n",
        "head(autompg1)\n",
        "class(autompg1$V1)\n",
        "class(autompg1$V2)\n",
        "class(autompg1$V3)\n",
        "class(autompg1$V4)\n",
        "class(autompg1$V5)\n",
        "class(autompg1$V6)\n",
        "class(autompg1$V7)\n",
        "class(autompg1$V8)\n",
        "class(autompg1$V9)\n",
        "\n",
        "\n",
        "# Data cleansing\n",
        "# 1. drop V9 since it is individual car name and meaningless in analysis\n",
        "autompg1$V9 <- NULL\n",
        "\n",
        "# 2. V4: character > numeric\n",
        "autompg1$V4 <- as.numeric(autompg1$V4)\n",
        "dim(autompg1)\n",
        "class(autompg1$V4)\n",
        "\n",
        "# 3. delete missing values: no missing values\n",
        "autompg1 <- na.omit(autompg1)\n",
        "dim(autompg1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 1: SIMPLE LINEAR REGRESSION ANALYSIS\n",
        "\n",
        "This part aims at examining the association between the response variable and a specific predictor \n",
        "variable you choose. In your report, make sure you\n",
        "\n",
        "### (1) Provide the justification of determining the response ð‘Œ and predictor ð‘‹ variables."
      ],
      "metadata": {
        "id": "5sUG3Ed4p0zx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "List of variables:\n",
        "\n",
        "1. mpg: continuous\n",
        "\n",
        "2. cylinders: multi-valued discrete\n",
        "\n",
        "3. displacement: continuous\n",
        "\n",
        "4. horsepower: continuous\n",
        "\n",
        "5. weight: continuous\n",
        "\n",
        "6. acceleration: continuous\n",
        "\n",
        "7. model year: multi-valued discrete\n",
        "\n",
        "8. origin: multi-valued discrete\n",
        "\n",
        "9. car name: string (unique for each instance)\n",
        "\n",
        "\n",
        "We chose the Auto MPG dataset. The dataset contains 398 observations with 9 variables (6 continuous, 3 discrete). The variables are listed above. Before conducting the analysis, had a data cleansing process of: 1)dropping the variable V9: car names, 2) changing the class of V4 variable from character to numeric, and 3)deleting rows with missing values (6 missing values were deleted, resulting in total of 392 observations).\n",
        "\n",
        "We would say that the fuel efficiency of a car is the most important factor that one would be interested in, and in this respect we selected MPG (Mileage per Gallon) as our response variable (Y). \n",
        "\n",
        "For determining the predictor variable, X, we first examined scatterplots of V2 ~ V8 to V1. According to the R results, V3: displacement, V4: horsepower, and V5: weight seemed to show the strongest relationship with the response variable, V1: auto MPG (See the below scatterplots). These three variables showed negative relationship with the response variable.\n",
        "Next, we examined the R square values when regressing each variable to auto mpg. (see the below results)\n",
        "We chose V5: Weight as the predictor variable because the variable showed the highest R square value of 0.6926.  \n"
      ],
      "metadata": {
        "id": "AqrQC0dnqg8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. scatter plot\n",
        "#v2: cyclinders : multi-valued discrete\n",
        "plot(V1~V2,data=autompg1,xlab=\"V2: cyclinders\",ylab=\"auto mpg\")\n",
        "\n",
        "#v3: displacement:continuous\n",
        "plot(V1~V3,data=autompg1,xlab=\"V3: displacement\",ylab=\"auto mpg\")\n",
        "\n",
        "#v4: horsepower :continuous\n",
        "plot(V1~V4,data=autompg1,xlab=\"V4: horsepower\",ylab=\"auto mpg\")\n",
        "\n",
        "#v5: weight :continuous\n",
        "plot(V1~V5,data=autompg1,xlab=\"V5: weight\",ylab=\"auto mpg\")\n",
        "\n",
        "#v6: acceleration :continuous\n",
        "plot(V1~V6,data=autompg1,xlab=\"V6: acceleration\",ylab=\"auto mpg\")\n",
        "\n",
        "#v7: model year : multi-valued discrete\n",
        "plot(V1~V7,data=autompg1,xlab=\"V7: model year\",ylab=\"auto mpg\")\n",
        "\n",
        "#v8: origin : multi-valued discrete\n",
        "plot(V1~V8,data=autompg1,xlab=\"V8: origin\",ylab=\"auto mpg\")\n"
      ],
      "metadata": {
        "id": "tGkmB5d5p-Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. summary\n",
        "v2<-lm(V1~V2,data=autompg1)\n",
        "summary(v2)\n",
        "\n",
        "v3<-lm(V1~V3,data=autompg1)\n",
        "summary(v3)\n",
        "\n",
        "v4<-lm(V1~V4,data=autompg1)\n",
        "summary(v4)\n",
        "\n",
        "v5<-lm(V1~V5,data=autompg1)\n",
        "summary(v5)\n",
        "\n",
        "v6<-lm(V1~V6,data=autompg1)\n",
        "summary(v6)\n",
        "\n",
        "v7<-lm(V1~V7,data=autompg1)\n",
        "summary(v7)\n",
        "\n",
        "v8<-lm(V1~V8,data=autompg1)\n",
        "summary(v8)\n"
      ],
      "metadata": {
        "id": "n8kBheUuqtQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) Construct a scatterplot of ð‘Œ against ð‘‹. Comment on the association between the two variables.\n",
        "   - If the association is not linear, apply transformations on either ð‘Œ or ð‘‹, or on both, to make a linear model more appropriate for the transformed data.\n",
        "   - When transformations are used, re-construct a scatterplot of (transformed) ð‘Œ against (transformed) ð‘‹ and work on the transformed data for parts (3)-(7).\n",
        "   \n",
        "*Answer:*\n",
        "\n",
        "See the following scatterplot. X and Y show a negative relation, but it seems nonlinear so need for transformations are suggested. "
      ],
      "metadata": {
        "id": "B92wCdrKq16b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(V1~V5,data=autompg1,xlab=\"X: weight\",ylab=\"Y: auto mpg\")\n",
        "m<-lm(V1~V5,data=autompg1)\n"
      ],
      "metadata": {
        "id": "jAswC0_Iq3DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also examined a graph of e on the fitted values(see the below graph), and the graph is somewhat different from a random scattering. Thus, violations on the linear relationship between X and Y is suggested."
      ],
      "metadata": {
        "id": "COeM0Mf7rIqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# graph of e on fitted values\n",
        "plot(m$residuals~m$fitted.values,xlab=\"Fitted value\",ylab=\"Residual\")\n",
        "abline(h=0)"
      ],
      "metadata": {
        "id": "bWjDXJXFrNaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the graphical results, we concluded that some transformations on X and/or Y are suggested. Referring to the prototype learned from the lecture, we tried several transformations on X (exponential, inverse) and Y (log, square root, inverse). Based on the scatterplots after trnasformation, we concluded that log transformation on Y is most appropriate.Thus, we hereafter use the log of Y as the response variable in Part 1. We denote log Y as Y'."
      ],
      "metadata": {
        "id": "wdbLWXs1rRwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations on X: \n",
        "V5.exp=exp(autompg1$V5); V5.inv=1/autompg1$V5; \n",
        "\n",
        "autompg1$V5.exp <- V5.exp\n",
        "autompg1$V5.inv <- V5.inv\n",
        "\n",
        "\n",
        "names(autompg1)\n",
        "head(autompg1$V5.exp)\n",
        "\n",
        "#plot(V1~V5.exp,data=autompg1,xlab=\"exp(X): exp(weight)\",ylab=\"Y: auto mpg\") #not appropriate\n",
        "plot(V1~V5.inv,data=autompg1,xlab=\"1/X: 1/weight\",ylab=\"Y: auto mpg\")\n",
        "plot(V1~V5,data=autompg1,xlab=\"X: weight\",ylab=\"Y: auto mpg\")\n",
        "\n",
        "# Transformations on Y: \n",
        "V1.log=log10(autompg1$V1); V1.sqrt=sqrt(autompg1$V1);V1.inv=1/(autompg1$V1);\n",
        "autompg1$V1.log <- V1.log\n",
        "autompg1$V1.sqrt <- V1.sqrt\n",
        "autompg1$V1.inv <- V1.inv\n",
        "\n",
        "plot(V1.log~V5,data=autompg1,xlab=\"Weight\",ylab=expression(paste(Log[10],\"(Auto MPG)\")))\n",
        "plot(V1.sqrt~V5,data=autompg1,xlab=\"Weight\",ylab=expression(paste(sqrt,\"(Auto MPG)\")))\n",
        "plot(V1.inv~V5,data=autompg1,xlab=\"Weight\",ylab=expression(paste(\"(1/Auto MPG)\")))\n"
      ],
      "metadata": {
        "id": "ax7V23ZkrTlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3) Regress (transformed) ð‘Œ on (transformed) ð‘‹. State the estimated regression function and superimpose it on the scatterplot."
      ],
      "metadata": {
        "id": "sIU0UUr-rhlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# regress\n",
        "\n",
        "m1<-lm(V1.log~V5,data=autompg1); summary(m1)\n",
        "\n",
        "plot(V1.log~V5,data=autompg1,xlab=\"Weight\",ylab=expression(paste(Log[10],\"(Auto MPG)\")))\n",
        "abline(m1,col=\"red\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MmYEt-ghr1Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "Regression function:  $$ Y'= 1.799 - 0.0001522X + \\epsilon$$\n",
        "\n",
        "\n",
        "### (4) Report the values of MSE and R^2. Interpret them, respectively, in the context of the problem.\n"
      ],
      "metadata": {
        "id": "n-408vxGr9ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(V1.log~V5,data=autompg1,xlab=\"Weight\",ylab=expression(paste(Log[10],\"(Auto MPG)\")))\n",
        "m1<-lm(V1.log~V5,data=autompg1)\n",
        "abline(m1,col=\"red\")\n",
        "summary(m1)\n",
        "\n",
        "anova(m1)\n",
        "sum(m1$residuals^2) \n",
        "summary(m1)$sigma^2"
      ],
      "metadata": {
        "id": "plbOccQKsCIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "Based on the output, the coefficient of determination is R^2= 0.7668, which means 76.68% of the variation in log10(Mileage per Gallon) can be accounted by Weight of the car into the regression model.\n",
        "The value of Mean Squared Error(MSE) is 0.005099282. The MSE that we get is pretty small, which means we get the good estimator. The above data is scattered wildly around the regression line, so 0.005099282 is as good as it gets.\n",
        "\n",
        "\n",
        "### (5) Test whether ð›½1 is different from zero or not at 0.05 level of significance. State the alternatives, the value of test statistic, p-value, and your conclusion."
      ],
      "metadata": {
        "id": "F41Kw0kVsGiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(m1)\n",
        "n <- nrow(autompg1)\n",
        "n\n",
        "qt(0.975,n-2) ## t-crit value\n",
        "tstat <- -1.522e-04/4.252e-06 ## t-stat\n",
        "tstat"
      ],
      "metadata": {
        "id": "n-_91SA4sKJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "(1) Alternatives:\n",
        "$H_{0}$: $\\beta$ 1 = 0 $H_{a}$: $\\beta$ 1 $\\neq$ 0\n",
        "\n",
        "(2) Decision rule: \n",
        "\n",
        "Critical value method: if |t*|  is less than or equal to the t-critical value, 1.966065, conclude Ho, if abs(t-stat) > t-critical value, 1.966065, then conclude Ha.\n",
        "\n",
        "P-value Method : if the p-value of the test is less than alpha = 0.05, conclude Ha.\n",
        "\n",
        "(3) The Value of test statistic, p-value and Conclusion\n",
        "\n",
        "t-stat is -35.79492, in which the absolute value is larger than the t critical value, 1.966065, so we conclude Ha and conclude that there is a linear association between X and log Y.\n",
        "\n",
        "p-value is 2.2e-16, which is smaller than the alpha = 0.05 so we conclude Ha. \n",
        "\n",
        "In conclusion, we can conclude that there exists a linear relationship between the log of auto MPG(V1) and weight (V5). \n",
        "\n",
        "\n",
        "### (6) Superimpose the (pointwise) 90% confidence band on the scatterplot."
      ],
      "metadata": {
        "id": "fQnjhwSYsO4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(V1.log~autompg1$V5,data=autompg1,xlab=\"Weight\",ylab=expression(paste(Log[10],\"(Auto MPG)\"))) + abline(m1,col=\"red\")\n",
        "m1<-lm(V1.log~V5,data=autompg1)\n",
        "summary(autompg1$V5)\n",
        "newx=seq(1613,5140,by=5)\n",
        "ci90=predict(m1,newdata=data.frame(V5=newx),level=0.90,interval=\"confidence\")\n",
        "lines(newx,ci90[,2],col=\"blue\"); lines(newx,ci90[,3],col=\"blue\") "
      ],
      "metadata": {
        "id": "QbmaBQ7DsSGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "See the plot above.\n",
        "\n",
        "\n",
        "### (7) Construct a scatterplot of semi-studentized residuals against the predicted values and a normal probability plot of semi-studentized residuals. Perform model diagnostics using the two plots.\n"
      ],
      "metadata": {
        "id": "MSlYcfcgsXv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot of semi-studentized residuals against predicted values\n",
        "plot(m1$residuals/summary(m1)$sigma~m1$fitted.values,xlab=\"predicted\",ylab=\"Semistudentized residual\")\n",
        "abline(h=0)\n",
        "\n",
        "\n",
        "## Normal probability plot of semistudentized residuals\n",
        "qqnorm(m1$residuals/summary(m1)$sigma,main=\"Normal Q-Q plot of residuals\"); qqline(m1$residuals/summary(m1)$sigma)\n"
      ],
      "metadata": {
        "id": "xjj0xU45sfer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatterplot of semi-studentized residuals against the predicted value can show three things: (1) linearity (linear relationship between X and Y'), (2) constant variance of error terms, and (3) presence of outliers. The scatterplot shows fairly random plot, which suggests no violation on linearity. In addition, if you draw two horizontal lines on the scatterplot, the width from left to right is not so different, indicating no violation of constant variance of error terms assumption. Lastly, there are no observations in which |e*| > 4 so there seems to be no outliers. Thus, based on the scatterplot, there is no suggestion of violations of assumptions. \n",
        "\n",
        "The normal probability plot shows some points on the far left side and far right side departing from the linear line, but the departure is not significant and  most of the scatter points fall on the straight line. This suggests the normal assumption for the error terms is not violated .Therefore, the normal probability plot below does not indicate any violation of the normality assumption.\n",
        "\n",
        "\n",
        "\n",
        "## PART 2: MULTIPLE LINEAR REGRESSION ANALYSIS\n",
        "\n",
        "This part aims at building a linear model using a set of potential predictor variables. In your report, \n",
        "make sure you include analyses for the following models.\n",
        "\n",
        "## Model #1: a regression model including three numerical predictor variables that you think are associated with the response variable.\n",
        "\n",
        "Based on the result of the scatterplots and the summary results, we selected three numerical predictor variables of the following: V3: displacement, V4: horsepower, and V5: weight. In this part, we did not use any transformations on the original variables. \n",
        "\n",
        "Since V5: weight was our independent variable in Part 1, we assigned V5(Weight) as X1 and V3(Displacement) and V4(Horsepower), the newly added variable, as X2, and X3 respectively. The response variable, Y, is V1(autoMPG).\n",
        "\n",
        "In other words, Y = V1(AutoMPG), X1 = V5(Weight), X2 = V3(Displacement), and X3 = V4(Horsepower). \n",
        "\n",
        "### (i) Produce an ANOVA table. Report SST, SSR, and SSE, and their corresponding degrees of freedom.\n"
      ],
      "metadata": {
        "id": "OwJKfgLEsjL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 <- lm(V1~V5+V3+V4,data=autompg1)\n",
        "summary(model1)\n",
        "anova(model1)\n",
        "\n",
        "#SSR\n",
        "ssr <- 16497.8 + 150.9 + 190.3\n",
        "ssr\n",
        "sse <- 6980.0\n",
        "sst <- ssr + sse\n",
        "sst\n",
        "\n",
        "dfr <- 3\n",
        "dfe <- 388\n",
        "dft <- dfr + dfe\n",
        "dft\n"
      ],
      "metadata": {
        "id": "Ya3yTmmYsnog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "SST: SSR + SSE = 16839 + 6980.0 = 23819\n",
        "df(total):  dfr + dfe = 3 + 388 = 391\n",
        "\n",
        "SSR: 16497.8 + 150.9 + 190.3 = 16839\n",
        "df(R): 1 + 1 + 1 = 3\n",
        "\n",
        "SSE: 6980.0\n",
        "df(E): 388 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### (ii) Perform the ð¹ð¹ test of overall linear relationship. State the alternatives, the value of test statistic, p-value, and your conclusion."
      ],
      "metadata": {
        "id": "56Ww801isr7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anova(model1)\n",
        "summary(model1)"
      ],
      "metadata": {
        "id": "y87kzkyesuWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "(1) Alternatives: \n",
        "$H_{0}$: $\\beta$ 1 = $\\beta$ 2 = $\\beta$ 3 = 0 \n",
        "$H_{a}$: At least one $\\beta$ k $\\neq$ 0\n",
        "\n",
        "(2) value of test statistic, p-value, and conclusion: \n",
        "\n",
        "The test statistic, F* is 312.\n",
        "\n",
        "p-value is 2.2e-16.\n",
        "\n",
        "Since the p-value is smaller than the alpha = 0.05 so we conclude Ha. In other words, we can conclude that at least one of the predictor variables have linear relationship with the response variable. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### (iii) Compute the extra sum of squares SSR(X3|X1, X2) and the coefficient of partial determination R^2Y3|12."
      ],
      "metadata": {
        "id": "miCTqk2xsw50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SSR(X3|X1, X2)\n",
        "m1m2 <- lm(V1~V5+V3,data=autompg1) # regression of V1(Y) on V5(X1) and V3(X2)\n",
        "m3 <- update(m1m2,~.+ V4) # regression of V1(Y) on V5, V3 & V4 \n",
        "anova(m1m2,m3)\n",
        "\n",
        "# extra sum of squares SSR(X3|X1, X2)\n",
        "7170.3 - 6980.0\n",
        "\n",
        "# Coefficient of partial determination: R square\n",
        "library(rsq)   #rsquare\n",
        "rsq.partial(m3,m1m2) # in R package 'rsq' #R square\n"
      ],
      "metadata": {
        "id": "WErkTwqUs1K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "extra sum of squares SSR(X3|X1, X2) : SSR(X3|X1, X2) = SSE(X1,X2) - SSE(X1,X2,X3) = 7170.3 - 6980.0 = 190.3\n",
        "\n",
        "coefficient of partial determination R^2Y3|12: 0.02653755\n",
        "\n",
        "\n",
        "\n",
        "### (iv) Test whether X3 is helpful, given that X1 and X2 are in a model. State the alternatives, the value of test statistic, p-value, and your conclusion."
      ],
      "metadata": {
        "id": "OYnDDtOWs5So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anova(m1m2,m3) # Testing H0: \\beta_[3}=0\n",
        "\n",
        "fstat <- ((7170.3 - 6980.0)/(389-388))/(6980.0/388)\n",
        "fstat\n",
        "fcrit <- qf(0.95,1,388)\n",
        "fcrit"
      ],
      "metadata": {
        "id": "Nz0BPsODs81k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "(1) Alternatives: $H_{0}$: $\\beta_3$  = 0  vs. $H_{a}$: $\\beta_3$ $\\neq$ 0\n",
        "\n",
        "(2) the value of test statistic, p-value, and conclusion:\n",
        "Test statisctic = F* = ((ssE(R)-SSE(F))/(dfR-dfF))/(SSE(F)/dfF) = ((7170.3-6980.0)/(389-388))/(6980.0/388) = 10.57828\n",
        "p-value = 0.001245\n",
        "\n",
        "Conclusion: Since p-value is smaller than alpha = 0.05, we conclude Ha. In other words, we conclude the full model, which includes X3 variable (V4: Horsepower). Thus the test result shows that X3 is helpful given that X1 and X2 are in a model. \n",
        "\n",
        "\n",
        "\n",
        "## Model #2: a regression model including a numerical predictor variable, a categorical predictor variable, and their interaction term.\n",
        "\n",
        "### (v) Incorporate the categorical variable into the model by defining indicator variable(s)."
      ],
      "metadata": {
        "id": "0UyfWczUtBmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unmodified regression model\n",
        "unique(autompg1$V2)\n",
        "model2 <- lm(V1~V5+V2+V2*V5,data=autompg1)\n",
        "summary(model2)\n",
        "\n",
        "#checking correlation btw V5 & V2\n",
        "cor(autompg1$V2, autompg1$V5)\n",
        "plot(V5~V2,data=autompg1,xlab=\"V2: cyclinders\",ylab=\"V5: Weight\")\n",
        "\n",
        "#modifications to X2\n",
        "library(dplyr)\n",
        "autompg11 <- autompg1%>%mutate(V2binary=case_when(V2<=4~0,TRUE~1))\n",
        "unique(autompg11$V2binary)\n",
        "cor(autompg11$V2binary, autompg11$V5)\n",
        "plot(V5~V2binary,data=autompg11,xlab=\"V2binary: cyclinders\",ylab=\"V5: Weight\")\n",
        "\n",
        "#removing unnecessary columns\n",
        "names(autompg11) \n",
        "autompg11$V5.exp <- NULL\n",
        "autompg11$V5.inv <- NULL\n",
        "autompg11$V1.sqrt <- NULL\n",
        "autompg11$V1.inv <- NULL\n",
        "names(autompg11) \n",
        "\n",
        "# Scatter plot matrix & Correlation matrix\n",
        "pairs(autompg11) \n",
        "round(cor(autompg11),digits=2) \n",
        "\n",
        "#modified regression model\n",
        "m.model2 <- lm(V1~V5+V2binary + V2binary*V5,data=autompg11)\n",
        "summary(m.model2)\n",
        "\n",
        "#interpretation of coefficients\n",
        "beta0 <- 4.956e+01\n",
        "beta1 <- -8.863e-03  \n",
        "beta2 <- -1.355e+01 \n",
        "beta12 <- 3.820e-03\n",
        "\n",
        "beta0 + beta2\n",
        "beta1 + beta12\n"
      ],
      "metadata": {
        "id": "ejd0QYultFTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "We included the V5: Weight as the numerical predictor variable, X1, and V2: cyclinders as the categorical predictor variable, X2, and also included their interaction term, X1X2. This was based on examining the scatterplots and R square values generated in Part 1. \n",
        "\n",
        "The possible values of the categorical variable X2 (V2 variable, cyclinders) are 3, 4, 5, 6, and 8. We first included the original variable, V2, without any modifications. However, because V5 has 5 possible values it is quite difficult to generate meaningful interpretations out of the result (see the below submodels and interpretation for the regression coefficinets). Also, we examined the scatterplot of V2 on V5 as well as the correlation coefficient and we find quite high correlation between the two variables. \n",
        "\n",
        "$\\hat{Y}$ = $\\beta_0$ + $\\beta_1$ * $X_{1}$ + $\\beta_2$ * $X_{2}$ + $\\beta_12$ * $X_{1}$ $X_{2}$\n",
        "\n",
        "1. Unmodified Model\n",
        "\n",
        "According to the R result, the fitted regression model is: \n",
        "\n",
        "$\\hat{Y}$ = 65.3864559 - 4.2097950 * $X_{1}$ -0.0128348 * $X_{2}$ + 0.0010979 * $X_{1}$ $X_{2}$\n",
        "\n",
        "\n",
        "The possible values of the categorical variable X2 (V2 variable, cyclinders) are 3, 4, 5, 6, and 8.\n",
        "\n",
        "Thus, we can generate 5 submodels : \n",
        "\n",
        "1) When X2 = 3: $\\hat{Y}$ = ($\\beta_0$ + 3$\\beta_2$) + ($\\beta_1$ + 3$\\beta_12$) * $X_{1}$\n",
        "\n",
        "2) When X2 = 4: $\\hat{Y}$ = ($\\beta_0$ + 4$\\beta_2$) + ($\\beta_1$ + 4$\\beta_12$) * $X_{1}$\n",
        "\n",
        "3) When X2 = 5: $\\hat{Y}$ = ($\\beta_0$ + 5$\\beta_2$) + ($\\beta_1$ + 5$\\beta_12$) * $X_{1}$\n",
        "\n",
        "4) When X2 = 6: $\\hat{Y}$ = ($\\beta_0$ + 6$\\beta_2$) + ($\\beta_1$ + 6$\\beta_12$) * $X_{1}$\n",
        "\n",
        "5) When X2 = 8: $\\hat{Y}$ = ($\\beta_0$ + 8$\\beta_2$) + ($\\beta_1$ + 8$\\beta_12$) * $X_{1}$\n",
        "\n",
        "$\\beta_2$ has no practical meaning here because there are no observations with cars with cyclinders = 0. \n",
        "\n",
        "$\\beta_12$ also has no practical meaning here.\n",
        "\n",
        "\n",
        "So, for ease of analysis and interpretation, we decide to make modifications to the categorical variable, V2, by assigning 0 in case X2(=V2) $\\le$ 4 and 1 in case X2(=V2) > 4. In other words, the modified X2 will have the following values: \n",
        "\n",
        "- $X_{2}$ = 0 if V2 = 3, 4\n",
        "\n",
        "- $X_{2}$ = 1 if V2 = 5, 6, 8\n",
        "\n",
        "2. Modified Model\n",
        "\n",
        "According to the R result, the modified fitted regression model is as follows.\n",
        "\n",
        "$\\hat{Y}$ = $\\beta_0$ + $\\beta_1$ * $X_{1}$ + $\\beta_2$ * $X_{2}$ + $\\beta_12$ * $X_{1}$ $X_{2}$\n",
        "\n",
        "$\\hat{Y}$ = 49.56 - 0.008863 * $X_{1}$ - 13.55 * $X_{2}$ + 0.003820 * $X_{1}$ $X_{2}$\n",
        "\n",
        "\n",
        "The possible values of the categorical variable X2(modified)  are 0 and 1.\n",
        "\n",
        "And according to the result, \n",
        "$\\beta_0$ =  49.56,\n",
        "$\\beta_1$ = - 0.008863,\n",
        "$\\beta_2$ = - 13.55,\n",
        "$\\beta_12$ = 0.003820.\n",
        "\n",
        "Thus, we can generate 2 submodels : \n",
        "\n",
        "1) When X2 = 0: \n",
        "\n",
        "     $\\hat{Y}$ = $\\beta_0$ + $\\beta_1$ * $X_{1}$ \n",
        "\n",
        "     = 49.56 - 0.008863 * $X_{1}$ \n",
        "\n",
        "2) When X2 = 1: \n",
        "\n",
        "     $\\hat{Y}$ = ($\\beta_0$ + $\\beta_2$) + ($\\beta_1$ + $\\beta_12$) * $X_{1}$ \n",
        "\n",
        "     = (49.56 + - 13.55) + (- 0.008863 + 0.003820) * $X_{1}$ \n",
        "\n",
        "     = 36.01 - 0.005043 * $X_{1}$\n",
        "\n",
        "\n",
        "### (vi) Interpret the coefficient of the categorical variable and that of the interaction term, respectively.\n",
        "\n",
        "*Answer:*\n",
        "\n",
        "\n",
        "$\\beta_2$ is the increment in the value of the intercept when for the group with X2=1 compared with the group with X2=0. In other words, $\\beta_2$ =-13.55 means that holding X1 constant, auto MPG is 13.55 lower for group with X2 = 1 compared with group with X2 =0. \n",
        "\n",
        "$\\beta_12$ is the incremental slope of the for the group with X2=1. In other words, $\\beta_12$ = 0.003820 means that for every one-unit increase in weight(X1), auto MPG increases by 0.003820 more for group with X2 = 1 (cyclinders =5,6,8) compared with the corresponding increase in auto MPG for croup with X2 = 0 (cyclinders = 3.4).\n",
        "\n",
        "\n",
        "### (vii) Should you drop the interaction term? Explain."
      ],
      "metadata": {
        "id": "o4u27Dcut2D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Partial F test\n",
        "model2_1 <- lm(V1~V2binary+V5,autompg11) #reduced model:H0\n",
        "model2_2 <- lm(V1~V2binary+V5+V2binary*V5,autompg11) #full model:Ha\n",
        "anova(model2_1,model2_2)"
      ],
      "metadata": {
        "id": "G5N7z1sWt5F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "Testing $H_{0}$: $\\beta_12$  = 0 (Reduced model) vs. $H_{a}$: $\\beta_12$ $\\neq$ 0 (Full model)\n",
        "\n",
        "The p-value = 0.0001373 < alpha = 0.05 so we conclude Ha. In other words, the full model, which includes the interaction term, is statistically better than the reduced model. So we should not drop the interaction term. \n",
        "\n",
        "\n",
        "## Model #3: building the â€œbestâ€ regression model using all potential predictor variables (with no interaction terms).\n",
        "\n",
        "### (viii) Use the AIC criterion and â€œbackward eliminationâ€ procedure to obtain the â€œbestâ€ model. Report the subset of predictor variables to be included in the model and the corresponding AIC value."
      ],
      "metadata": {
        "id": "NIm7Xl7suAzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modify 'autompg11' > delete 'V1.log' and V2 (leave only V2binary)\n",
        "autompg2 <- autompg11\n",
        "names(autompg2)\n",
        "autompg2$V1.log <- NULL\n",
        "autompg2$V2 <- NULL\n",
        "names(autompg2)\n",
        "dim(autompg2)\n",
        "\n",
        "#AIC\n",
        "#install.packages(\"ALSM\")\n",
        "library(ALSM)\n",
        "\n",
        "class(autompg2$V1)\n",
        "model3 <- lm(V1~V2binary+V3+V4+V5+V6+V7+V8,autompg2)\n",
        "model3.backward<-step(model3,direction=\"backward\") # backward elimination by AIC\n",
        "summary(model3.backward)\n"
      ],
      "metadata": {
        "id": "gKekGSZUuEpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer:*\n",
        "\n",
        "According to the R result using AIC criterion and â€œbackward eliminationâ€ procedure, the best model should include all variables except V6: Acceleration. The fitted model is as follows. The corresponding AIC value is 918.2.\n",
        "\n",
        "\n",
        "$\\hat{Y}$ = -17.19 - 3.805 * $X_{1}$ + 0.02749 * $X_{2}$ - 0.04071 * $X_{3}$ + - 0.005641 * $X_{4}$ + 0.7378 * $X_{5}$ + 1.344 * $X_{6}$\n",
        "\n",
        "where \n",
        "\n",
        "Y =  auto MPG\n",
        "\n",
        "$X_{1}$ =  0 if cyclinders = 3, 4; 1 if cyclinders = 5, 6, 8\n",
        "\n",
        "$X_{2}$ =  Displacement\n",
        "\n",
        "$X_{3}$ =  Horsepower\n",
        "\n",
        "$X_{4}$ =  Weight\n",
        "\n",
        "$X_{5}$ =  Model Year\n",
        "\n",
        "$X_{6}$ =  Origin\n",
        " "
      ],
      "metadata": {
        "id": "NSkmrThSuJF4"
      }
    }
  ]
}